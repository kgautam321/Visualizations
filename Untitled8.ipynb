{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled8.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kgautam321/Visualizations/blob/master/Untitled8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loCPevHGJGwe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "#gktest\n",
        "\"\"\"\n",
        "Created on Sat Jul 13 13:52:34 2019\n",
        "\n",
        "@author: Dieudonne Ouedraogo\n",
        "\n",
        "A simple deep newral network using python's deep learning package Keras \n",
        "to predict if a customer with specific charasteristic will churn as client\n",
        "using articial neural network\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Importing the  necessary libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "#----------------Data Preprocessing--------------------\n",
        "\n",
        "# Import the dataset\n",
        "dataset = pd.read_csv('Churn_Modelling.csv')\n",
        "# locate the positions of the features to be used for the model\n",
        "X = dataset.iloc[:, 3:13].values\n",
        "#locate the position of the label or outcome /output\n",
        "y = dataset.iloc[:, 13].values \n",
        "\n",
        "# Encode the categorical data to numeric data\n",
        "# to feed the ANN, algorithms implemenation in sklearn and keras use numerics\n",
        "\n",
        "labelencoder_X_1 = LabelEncoder()\n",
        "X[:, 1] = labelencoder_X_1.fit_transform(X[:, 1])\n",
        "\n",
        "labelencoder_X_2 = LabelEncoder()\n",
        "X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])\n",
        "onehotencoder = OneHotEncoder(categorical_features = [1])\n",
        "X = onehotencoder.fit_transform(X).toarray()\n",
        "\n",
        "#Remove dummie variable\n",
        "X = X[:, 1:]\n",
        "\n",
        "# Splitting the dataset into the Training set and Test set\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 42)\n",
        "\n",
        "# Feature Scaling\n",
        "\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "#  ------------------Build the neural network model-------------------------\n",
        "\n",
        "\n",
        "# Instantiation = Initialising the neural network object,it's a sequential model\n",
        "classifier = Sequential()\n",
        "\n",
        "\n",
        "#We have 11 features which are the input nodes, so input_dim =11: \n",
        "# We will add two hidden layers with 6 nodes each \n",
        "# We will use a relu activation function on those two hidden layer\n",
        "# We need just one node as output node to represent the state of the churn, 1 or 0.\n",
        "# We will use sigmoid as activation function on this node\n",
        "# We use adam optimizer and binary_crossentropy as the loss\n",
        "# we train on batch size of 10 and run 50 epochs over the data.\n",
        "\n",
        "# First hidden layer\n",
        "classifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu', input_dim = 11))\n",
        "\n",
        "# Second hidden \n",
        "classifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu'))\n",
        "\n",
        "# Add the Output layer\n",
        "classifier.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))\n",
        "\n",
        "\n",
        "#Compiling the neural network\n",
        "# binary_crossentropy loss function used when a binary output is expected\n",
        "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy']) \n",
        "\n",
        "# Fit the classifier to the Training set\n",
        "classifier.fit(X_train, y_train, batch_size = 10, nb_epoch = 50)\n",
        "\n",
        "\n",
        "\n",
        "# Predict using the Test set \n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Set up a treshold and filter who will leave or not\n",
        "y_pred = (y_pred > 0.5)\n",
        "\n",
        "# Compute the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "cm\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}